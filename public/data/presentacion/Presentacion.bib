@online{ahmedEnhancingBreastCancer2024,
    title       = {Enhancing {{Breast Cancer Diagnosis}} in {{Mammography}}: {{Evaluation}} and {{Integration}} of {{Convolutional Neural Networks}} and {{Explainable AI}}},
    shorttitle  = {Enhancing {{Breast Cancer Diagnosis}} in {{Mammography}}},
    author      = {Ahmed, Maryam and Bibi, Tooba and Khan, Rizwan Ahmed and Nasir, Sidra},
    date        = {2024-04-27},
    eprint      = {2404.03892},
    eprinttype  = {arXiv},
    eprintclass = {cs, eess},
    url         = {http://arxiv.org/abs/2404.03892},
    urldate     = {2024-05-15},
    abstract    = {The Deep learning (DL) models for diagnosing breast cancer from mammographic images often operate as ”black boxes,” making it difficult for healthcare professionals to trust and understand their decision-making processes. The study presents an integrated framework combining Convolutional Neural Networks (CNNs) and Explainable Artificial Intelligence (XAI) for the enhanced diagnosis of breast cancer using the CBIS-DDSM dataset. The methodology encompasses an elaborate data preprocessing pipeline and advanced data augmentation techniques to counteract dataset limitations and transfer learning using pre-trained networks such as VGG-16, Inception-V3 and ResNet was employed. A focal point of our study is the evaluation of XAI’s effectiveness in interpreting model predictions, highlighted by utilising the Hausdorff measure to assess the alignment between AI-generated explanations and expert annotations quantitatively. This approach is critical for XAI in promoting trustworthiness and ethical fairness in AI-assisted diagnostics. The findings from our research illustrate the effective collaboration between CNNs and XAI in advancing diagnostic methods for breast cancer, thereby facilitating a more seamless integration of advanced AI technologies within clinical settings. By enhancing the interpretability of AIdriven decisions, this work lays the groundwork for improved collaboration between AI systems and medical practitioners, ultimately enriching patient care. Furthermore, the implications of our research extended well beyond the current methodologies. It encourages further research into how to combine multimodal data and improve AI explanations to meet the needs of clinical practice.},
    langid      = {english},
    pubstate    = {prepublished},
    keywords    = {Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Electrical Engineering and Systems Science - Image and Video Processing},
    file        = {/home/caribu/Zotero/storage/BHXG82LP/Ahmed et al. - 2024 - Enhancing Breast Cancer Diagnosis in Mammography .pdf}
}

@article{gerbasiDeepMiCaAutomaticSegmentation2023,
    title        = {{{DeepMiCa}}: {{Automatic}} Segmentation and Classification of Breast {{MIcroCAlcifications}} from Mammograms},
    shorttitle   = {{{DeepMiCa}}},
    author       = {Gerbasi, Alessia and Clementi, Greta and Corsi, Fabio and Albasini, Sara and Malovini, Alberto and Quaglini, Silvana and Bellazzi, Riccardo},
    date         = {2023-06-01},
    journaltitle = {Computer Methods and Programs in Biomedicine},
    shortjournal = {Computer Methods and Programs in Biomedicine},
    volume       = {235},
    pages        = {107483},
    issn         = {0169-2607},
    doi          = {10.1016/j.cmpb.2023.107483},
    url          = {https://www.sciencedirect.com/science/article/pii/S0169260723001499},
    urldate      = {2025-07-15},
    abstract     = {Background and objective Breast cancer is the world’s most prevalent form of cancer. The survival rates have increased in the last years mainly due to factors such as screening programs for early detection, new insights on the disease mechanisms as well as personalised treatments. Microcalcifications are the only first detectable sign of breast cancer and diagnosis timing is strongly related to the chances of survival. Nevertheless microcalcifications detection and classification as benign or malignant lesions is still a challenging clinical task and their malignancy can only be proven after a biopsy procedure. We propose DeepMiCa, a fully automated and visually explainable deep-learning based pipeline for the analysis of raw mammograms with microcalcifications. Our aim is to propose a reliable decision support system able to guide the diagnosis and help the clinicians to better inspect borderline difficult cases. Methods DeepMiCa is composed by three main steps: (1) Preprocessing of the raw scans (2) Automatic patch-based Semantic Segmentation using a UNet based network with a custom loss function appositely designed to deal with extremely small lesions (3) Classification of the detected lesions with a deep transfer-learning approach. Finally, state-of-the-art explainable AI methods are used to produce maps for a visual interpretation of the classification results. Each step of DeepMiCa is designed to address the main limitations of the previous proposed works resulting in a novel automated and accurate pipeline easily customisable to meet radiologists’ needs. Results The proposed segmentation and classification algorithms achieve an area under the ROC curve of 0.95 and 0.89 respectively. Compared to previously proposed works, this method does not require high performance computational resources and provides a visual explanation of the final classification results. Conclusion To conclude, we designed a novel fully automated pipeline for detection and classification of breast microcalcifications. We believe that the proposed system has the potential to provide a second opinion in the diagnosis process giving the clinicians the opportunity to quickly visualise and inspect relevant imaging characteristics. In the clinical practice the proposed decision support system could help reduce the rate of misclassified lesions and consequently the number of unnecessary biopsies.},
    keywords     = {Classification,Deep learning,Explainability,Mammograms,Microcalcifications,Segmentation},
    file         = {/home/caribu/Zotero/storage/SXDG9J56/Gerbasi et al. - 2023 - DeepMiCa Automatic segmentation and classification of breast MIcroCAlcifications from mammograms.pdf;/home/caribu/Zotero/storage/VU3ZC6DA/S0169260723001499.html}
}

@dataset{andrioleRSNAScreeningMammography2022,
    title     = {{{RSNA Screening Mammography Breast}}  {{Cancer Detection Challenge}}},
    author    = {Andriole, Katherine P. and Ball, Robyn and Chen, Yan and Frazer, Helen and Kitamura, Felipe and Kwok, Jackson and Lungren, Matthew and Mann, Ritse and Mongan, John and Partridge, George and Moy, Linda and Trivedi, Hari and Wang, Xin and Yao, Luyan and Zhang, Tianyu},
    date      = {2022},
    publisher = {Kaggle},
    url       = {https://www.kaggle.com/competitions/rsna-breast-cancer-detection},
    langid    = {english}
}

@article{azamMammographicMicrocalcificationsRisk2021,
    title        = {Mammographic Microcalcifications and Risk of Breast Cancer},
    author       = {Azam, Shadi and Eriksson, Mikael and Sjölander, Arvid and Gabrielson, Marike and Hellgren, Roxanna and Czene, Kamila and Hall, Per},
    date         = {2021-08},
    journaltitle = {British Journal of Cancer},
    shortjournal = {Br J Cancer},
    volume       = {125},
    number       = {5},
    pages        = {759--765},
    publisher    = {Nature Publishing Group},
    issn         = {1532-1827},
    doi          = {10.1038/s41416-021-01459-x},
    url          = {https://www.nature.com/articles/s41416-021-01459-x},
    urldate      = {2024-08-01},
    abstract     = {Mammographic microcalcifications are considered early signs of breast cancer (BC). We examined the association between microcalcification clusters and the risk of overall and subtype-specific BC. Furthermore, we studied how mammographic density (MD) influences the association between microcalcification clusters and BC risk.},
    langid       = {english},
    keywords     = {Breast cancer,Cancer epidemiology},
    file         = {/home/caribu/Zotero/storage/IW9K8DP5/Azam et al. - 2021 - Mammographic microcalcifications and risk of breas.pdf}
}

@unpublished{barnettIAIABLCasebasedInterpretable2021,
    title       = {{{IAIA-BL}}: {{A Case-based Interpretable Deep Learning Model}} for {{Classification}} of {{Mass Lesions}} in {{Digital Mammography}}},
    shorttitle  = {{{IAIA-BL}}},
    author      = {Barnett, Alina Jade and Schwartz, Fides Regina and Tao, Chaofan and Chen, Chaofan and Ren, Yinhao and Lo, Joseph Y. and Rudin, Cynthia},
    date        = {2021-03-23},
    eprint      = {2103.12308},
    eprinttype  = {arXiv},
    eprintclass = {cs},
    publisher   = {arXiv},
    url         = {http://arxiv.org/abs/2103.12308},
    urldate     = {2022-05-24},
    abstract    = {Interpretability in machine learning models is important in high-stakes decisions, such as whether to order a biopsy based on a mammographic exam. Mammography poses important challenges that are not present in other computer vision tasks: datasets are small, confounding information is present, and it can be difficult even for a radiologist to decide between watchful waiting and biopsy based on a mammogram alone. In this work, we present a framework for interpretable machine learning-based mammography. In addition to predicting whether a lesion is malignant or benign, our work aims to follow the reasoning processes of radiologists in detecting clinically relevant semantic features of each image, such as the characteristics of the mass margins. The framework includes a novel interpretable neural network algorithm that uses case-based reasoning for mammography. Our algorithm can incorporate a combination of data with whole image labelling and data with pixel-wise annotations, leading to better accuracy and interpretability even with a small number of images. Our interpretable models are able to highlight the classification-relevant parts of the image, whereas other methods highlight healthy tissue and confounding information. Our models are decision aids, rather than decision makers, aimed at better overall human-machine collaboration. We do not observe a loss in mass margin classification accuracy over a black box neural network trained on the same data.},
    keywords    = {Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,I.2.10,I.2.6,I.4.9},
    file        = {/home/caribu/Zotero/storage/XZVGJB8W/Barnett et al. - 2021 - IAIA-BL A Case-based Interpretable Deep Learning .pdf;/home/caribu/Zotero/storage/4HWVDVAI/2103.html}
}

@article{caoBreastMassDetection2021,
    title        = {Breast Mass Detection in Digital Mammography Based on Anchor-Free Architecture},
    author       = {Cao, Haichao and Pu, Shiliang and Tan, Wenming and Tong, Junyan},
    date         = {2021-06-01},
    journaltitle = {Computer Methods and Programs in Biomedicine},
    shortjournal = {Computer Methods and Programs in Biomedicine},
    volume       = {205},
    pages        = {106033},
    issn         = {0169-2607},
    doi          = {10.1016/j.cmpb.2021.106033},
    url          = {https://www.sciencedirect.com/science/article/pii/S0169260721001085},
    urldate      = {2023-01-05},
    abstract     = {Background and objective Accurate detection of breast masses in mammography images is critical to diagnose early breast cancer, which can greatly improve the patients’ survival rate. However, it is still a big challenge due to the heterogeneity of breast masses and the complexity of their surrounding environment. Therefore, how to develop a robust breast mass detection framework in clinical practical applications to improve patient survival is a topic that researchers need to continue to explore. Methods To address these problems, we propose a one-stage object detection architecture, called Breast Mass Detection Network (BMassDNet), based on anchor-free and feature pyramid which makes the detection of breast masses of different sizes well adapted. We introduce a truncation normalization method and combine it with adaptive histogram equalization to enhance the contrast between the breast mass and the surrounding environment. Meanwhile, to solve the overfitting problem caused by small data size, we propose a natural deformation data augmentation method and mend the train data dynamic updating method based on the data complexity to effectively utilize the limited data. Finally, we use transfer learning to assist the training process and to improve the robustness of the model ulteriorly. Results On the INbreast dataset, each image has an average of 0.495 false positives whilst the recall rate is 0.930; On the DDSM dataset, when each image has 0.599 false positives, the recall rate reaches 0.943. Conclusions The experimental results on datasets INbreast and DDSM show that the proposed BMassDNet can obtain competitive detection performance over the current top ranked methods.},
    langid       = {english},
    keywords     = {Anchor-free architecture,aumentacion,breast cancer,Breast mass detection,CLAHE,Data augmentation method,Image enhancement method,Training method},
    file         = {/home/caribu/Zotero/storage/YVEKK9WQ/Cao et al. - 2021 - Breast mass detection in digital mammography based.pdf;/home/caribu/Zotero/storage/PKM5GLDM/S0169260721001085.html}
}

@article{cerekciQuantitativeEvaluationSaliencyBased2024,
    title        = {Quantitative Evaluation of {{Saliency-Based Explainable}} Artificial Intelligence ({{XAI}}) Methods in {{Deep Learning-Based}} Mammogram Analysis},
    author       = {Cerekci, Esma and Alis, Deniz and Denizoglu, Nurper and Camurdan, Ozden and Ege Seker, Mustafa and Ozer, Caner and Hansu, Muhammed Yusuf and Tanyel, Toygar and Oksuz, Ilkay and Karaarslan, Ercan},
    date         = {2024-04-01},
    journaltitle = {European Journal of Radiology},
    shortjournal = {European Journal of Radiology},
    volume       = {173},
    pages        = {111356},
    issn         = {0720-048X},
    doi          = {10.1016/j.ejrad.2024.111356},
    url          = {https://www.sciencedirect.com/science/article/pii/S0720048X2400072X},
    urldate      = {2024-05-15},
    abstract     = {Background Explainable Artificial Intelligence (XAI) is prominent in the diagnostics of opaque deep learning (DL) models, especially in medical imaging. Saliency methods are commonly used, yet there's a lack of quantitative evidence regarding their performance. Objectives To quantitatively evaluate the performance of widely utilized saliency XAI methods in the task of breast cancer detection on mammograms. Methods Three radiologists drew ground-truth boxes on a balanced mammogram dataset of women (n~=~1496 cancer-positive and negative scans) from three centers. A modified, pre-trained DL model was employed for breast cancer detection, using MLO and CC images. Saliency XAI methods, including Gradient-weighted Class Activation Mapping (Grad-CAM), Grad-CAM++, and Eigen-CAM, were evaluated. We utilized the Pointing Game to assess these methods, determining if the maximum value of a saliency map aligned with the bounding boxes, representing the ratio of correctly identified lesions among all cancer patients, with a value ranging from 0 to 1. Results The development sample included 2,244 women (75\%), with the remaining 748 women (25\%) in the testing set for unbiased XAI evaluation. The model's recall, precision, accuracy, and F1-Score in identifying cancer in the testing set were 69\%, 88\%, 80\%, and 0.77, respectively. The Pointing Game Scores for Grad-CAM, Grad-CAM++, and Eigen-CAM were 0.41, 0.30, and 0.35 in women with cancer and marginally increased to 0.41, 0.31, and 0.36 when considering only true-positive samples. Conclusions While saliency-based methods provide some degree of explainability, they frequently fall short in delineating how DL models arrive at decisions in a considerable number of instances.},
    keywords     = {Breast Cancer,Deep Learning,Mammogram,XAI},
    file         = {/home/caribu/Zotero/storage/T8HKEYXG/Cerekci et al. - 2024 - Quantitative evaluation of Saliency-Based Explaina.pdf;/home/caribu/Zotero/storage/W67BHNFM/S0720048X2400072X.html}
}

@article{costaDiagnosticDelaysBreast2024,
    title        = {Diagnostic Delays in Breast Cancer among Young Women: {{An}} Emphasis on Healthcare Providers},
    shorttitle   = {Diagnostic Delays in Breast Cancer among Young Women},
    author       = {Costa, Luis and Kumar, Rakesh and Villarreal-Garza, Cynthia and Sinha, Saket and Saini, Sunil and Semwal, Jayanti and Saxsena, Vartika and Zamre, Vaishali and Chintamani, Chintamani and Ray, Mukurdipi and Shimizu, Chikako and Gusic, Lejla Hadzikadic and Toi, Masakazu and Lipton, Allan},
    date         = {2024-02-01},
    journaltitle = {The Breast},
    shortjournal = {The Breast},
    volume       = {73},
    pages        = {103623},
    issn         = {0960-9776},
    doi          = {10.1016/j.breast.2023.103623},
    url          = {https://www.sciencedirect.com/science/article/pii/S096097762300749X},
    urldate      = {2025-07-31},
    abstract     = {Despite advances in breast cancer care, breast cancer in young women (BCYW) faces unique challenges, diagnostic delays, and limited awareness in many countries. Here, we discuss the challenges and consequences associated with the delayed diagnosis of BCYW. The consequences of delayed diagnosis in young women - which generally varies among developed, developing, or underdeveloped countries - are severe due to a faster breast tumor growth rate than tumors in older women, also contributing to advanced cancer stages and poorer outcomes. Though there are many underlying reasons for diagnostic delays due to age, the article delves explicitly deep into the diagnostic delay of BCYW, focusing on healthcare providers, potential contributing factors, its consequences, and the urgent need to start minimizing such incidences. The article suggests several strategies to address these issues, including increasing awareness, developing educational programs for healthcare providers to identify signs and symptoms in young women, developing clear diagnostic guidelines, and improving screening strategies.},
    keywords     = {Awareness,BCYW foundation,Breast cancer in young women,Diagnostic delay,Early detection,Healthcare providers,Tumor growth},
    file         = {/home/caribu/Zotero/storage/7N4J5NJL/Costa et al. - 2024 - Diagnostic delays in breast cancer among young women An emphasis on healthcare providers.pdf;/home/caribu/Zotero/storage/JEHVW53Z/S096097762300749X.html}
}

@article{dahlTwostageMammographyClassification2023,
    title        = {Two-Stage Mammography Classification Model Using Explainable-{{AI}} for {{ROI}} Detection},
    author       = {Dahl, Fredrik and Brautaset, Olav and Holden, Marit and Eikvil, Line and Larsen, Marthe and Hofvind, Solveig},
    date         = {2023-11-17},
    journaltitle = {Nordic Machine Intelligence},
    shortjournal = {NMI},
    volume       = {3},
    number       = {2},
    pages        = {1--7},
    issn         = {2703-9196},
    doi          = {10.5617/nmi.10459},
    url          = {https://journals.uio.no/NMI/article/view/10459},
    urldate      = {2024-05-15},
    abstract     = {This study introduces an enhanced version of a two-stage modelling approach using artificial intelligence (AI) for breast cancer detection in mammography screening. Leveraging a large dataset of 2,863,175 mammograms from the BreastScreen Norway, the approach uses two convolutional neural networks. The first one is trained to classify whole images, and an explainable-AI method is applied to this network to identify a region of interest (ROI). The second neural network subsequently classifies the ROI for malignancy. While a prior method used simple gradient saliency maps to identify ROIs, a key enhancement of the present methodology is the application of Layered GradCam, which identifies cancerous areas more consistently and allows smaller ROIs. Layered GradCam is also used to display identified cancers to the user. By the AUC criterion, our model performs well, 0.974 for screen-detected and 0.931 for all cancers (screen-detected and interval), compared to a commercial program; 0.959 and 0.918, respectively. Comparisons with the radiologist scores indicate that the model has equal performance with two radiologists, and superior performance to one, for the detection of all cancers (screening- and interval type). Our tests indicate that our model generalizes well for different breast centers, but so far only images from a single manufacturer have been tested.},
    langid       = {english},
    file         = {/home/caribu/Zotero/storage/DVA8C5GX/Dahl et al. - 2023 - Two-stage mammography classification model using e.pdf}
}

@online{dasOpportunitiesChallengesExplainable2020,
    title       = {Opportunities and {{Challenges}} in {{Explainable Artificial Intelligence}} ({{XAI}}): {{A Survey}}},
    shorttitle  = {Opportunities and {{Challenges}} in {{Explainable Artificial Intelligence}} ({{XAI}})},
    author      = {Das, Arun and Rad, Paul},
    date        = {2020-06-23},
    eprint      = {2006.11371},
    eprinttype  = {arXiv},
    eprintclass = {cs},
    url         = {http://arxiv.org/abs/2006.11371},
    urldate     = {2024-11-07},
    abstract    = {Nowadays, deep neural networks are widely used in mission critical systems such as healthcare, self-driving vehicles, and military which have direct impact on human lives. However, the black-box nature of deep neural networks challenges its use in mission critical applications, raising ethical and judicial concerns inducing lack of trust. Explainable Artificial Intelligence (XAI) is a field of Artificial Intelligence (AI) that promotes a set of tools, techniques, and algorithms that can generate high-quality interpretable, intuitive, human-understandable explanations of AI decisions. In addition to providing a holistic view of the current XAI landscape in deep learning, this paper provides mathematical summaries of seminal work. We start by proposing a taxonomy and categorizing the XAI techniques based on their scope of explanations, methodology behind the algorithms, and explanation level or usage which helps build trustworthy, interpretable, and self-explanatory deep learning models. We then describe the main principles used in XAI research and present the historical timeline for landmark studies in XAI from 2007 to 2020. After explaining each category of algorithms and approaches in detail, we then evaluate the explanation maps generated by eight XAI algorithms on image data, discuss the limitations of this approach, and provide potential future directions to improve XAI evaluation.},
    langid      = {english},
    pubstate    = {prepublished},
    keywords    = {Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning},
    file        = {/home/caribu/Zotero/storage/S2JVHRBH/Das y Rad - 2020 - Opportunities and Challenges in Explainable Artificial Intelligence (XAI) A Survey.pdf}
}

@article{duAutomaticCalcificationMorphology2023,
    title        = {Automatic {{Calcification Morphology}} and {{Distribution Classification}} for {{Breast Mammograms With Multi-Task Graph Convolutional Neural Network}}},
    author       = {Du, Hao and Yao, Melissa Min-Szu and Liu, Siqi and Chen, Liangyu and Chan, Wing P. and Feng, Mengling},
    date         = {2023-08},
    journaltitle = {IEEE Journal of Biomedical and Health Informatics},
    shortjournal = {IEEE J. Biomed. Health Inform.},
    volume       = {27},
    number       = {8},
    pages        = {3782--3793},
    issn         = {2168-2194, 2168-2208},
    doi          = {10.1109/JBHI.2023.3249404},
    url          = {https://ieeexplore.ieee.org/document/10053998/},
    urldate      = {2025-12-17},
    langid       = {english},
    file         = {/home/caribu/Zotero/storage/YK6PFMMU/Du et al. - 2023 - Automatic Calcification Morphology and Distribution Classification for Breast Mammograms With Multi-.pdf}
}

@article{farragExplainableAISystem2023,
    title        = {An {{Explainable AI System}} for {{Medical Image Segmentation With Preserved Local Resolution}}: {{Mammogram Tumor Segmentation}}},
    shorttitle   = {An {{Explainable AI System}} for {{Medical Image Segmentation With Preserved Local Resolution}}},
    author       = {Farrag, Aya and Gad, Gad and Fadlullah, Zubair Md. and Fouda, Mostafa M. and Alsabaan, Maazen},
    date         = {2023},
    journaltitle = {IEEE Access},
    shortjournal = {IEEE Access},
    volume       = {11},
    pages        = {125543--125561},
    issn         = {2169-3536},
    doi          = {10.1109/ACCESS.2023.3330465},
    url          = {https://ieeexplore.ieee.org/document/10309920/},
    urldate      = {2024-06-06},
    abstract     = {Medical image segmentation aims to identify important or suspicious regions within medical images. However, many challenges are usually faced while developing networks for this type of analysis. First, preserving the original image resolution is of utmost importance for this task where identifying subtle features or abnormalities can significantly impact the accuracy of diagnosis. While introducing the dilated convolution improves the resolution of the convolutional neural network (CNN), it is not without shortcoming, i.e., the loss of local spatial resolution due to increased kernel sparsity in checkboard patterns. To address this shortcoming, we conceptualize a double-dilated convolution module for maintaining local spatial resolution while improving the receptive field size. Then, this approach is applied, as a proof-ofwork, to tumor segmentation task in mammograms. In addition, our proposal also tackles the class imbalance problem, originating at the pixel level of the mammogram screenings, by identifying and selecting the best candidate among a number of potential loss functions to facilitate mass segmentation. We also carry out quantitative and qualitative evaluations of the interpretability of our proposal by leveraging Grad-CAM (Gradient weighted Class Activation Map). We also present a comparative performance evaluation with existing explainable techniques tailored for segmenting images. Moreover, an empirical assessment on lesion segmentation is conducted on mammogram samples from the INBreast dataset, both with and without incorporating our envisaged dilation module into CNN. The obtained results elucidate the effectiveness of our proposal based on mass segmentation performance measures, such as Dice similarity and Miss Detection rate. Our analysis also promotes using the Tversky Loss function in training pixel-imbalanced data and integrating Grad-CAM for explaining image segmentation results.},
    langid       = {english},
    file         = {/home/caribu/Zotero/storage/Y83NEJ2I/Farrag et al. - 2023 - An Explainable AI System for Medical Image Segment.pdf}
}

@article{grande-barretoShortBreastImaging2024,
    title        = {A {{Short Breast Imaging Reporting}} and {{Data System-Based Description}} for {{Classification}} of {{Breast Mass Grade}}},
    author       = {Grande-Barreto, Jonas and Lopez-Armas, Gabriela C. and Sanchez-Tiro, Jose Antonio and Peregrina-Barreto, Hayde},
    date         = {2024-12},
    journaltitle = {Life},
    volume       = {14},
    number       = {12},
    pages        = {1634},
    publisher    = {Multidisciplinary Digital Publishing Institute},
    issn         = {2075-1729},
    doi          = {10.3390/life14121634},
    url          = {https://www.mdpi.com/2075-1729/14/12/1634},
    urldate      = {2025-12-17},
    abstract     = {Identifying breast masses is relevant in early cancer detection. Automatic identification using computational methods helps assist medical experts with this task. Although high values have been reported in breast mass classification from digital mammograms, most results have focused on a general benign/malignant classification. According to the BI-RADS standard, masses are associated with cancer risk by grade depending on their specific shape, margin, and density characteristics. This work presents a methodology of testing several descriptors on the INbreast dataset, finding those better related to clinical assessment. The analysis provides a description based on BI-RADS for mass classification by combining neural networks and image processing. The results show that masses associated with grades BI-RADS-2 to BI-RADS-5 can be identified, reaching a general accuracy and sensitivity of 0.88±0.07. While this initial study is limited to a single dataset, it demonstrates the possibility of generating a description for automatic classification that is directly linked to the information analyzed by medical experts in clinical practice.},
    langid       = {english},
    keywords     = {automatic classification,BI-RADS grade,breast masses,mass characterization},
    file         = {/home/caribu/Zotero/storage/4CQVF79X/Grande-Barreto et al. - 2024 - A Short Breast Imaging Reporting and Data System-Based Description for Classification of Breast Mass.pdf}
}

@article{gunningDARPAsExplainableArtificial2019,
    title        = {{{DARPA}}'s {{Explainable Artificial Intelligence Program}}},
    author       = {Gunning, David and Aha, David W.},
    date         = {2019},
    journaltitle = {AI Magazine},
    volume       = {40},
    number       = {2},
    pages        = {44--58},
    issn         = {2371-9621},
    doi          = {10.1609/aimag.v40i2.2850},
    url          = {https://onlinelibrary.wiley.com/doi/abs/10.1609/aimag.v40i2.2850},
    urldate      = {2024-11-07},
    abstract     = {Dramatic success in machine learning has led to a new wave of AI applications (for example, transportation, security, medicine, finance, defense) that offer tremendous benefits but cannot explain their decisions and actions to human users. DARPA's explainable artificial intelligence (XAI) program endeavors to create AI systems whose learned models and decisions can be understood and appropriately trusted by end users. Realizing this goal requires methods for learning more explainable models, designing effective explanation interfaces, and understanding the psychologic requirements for effective explanations. The XAI developer teams are addressing the first two challenges by creating ML techniques and developing principles, strategies, and human-computer interaction techniques for generating effective explanations. Another XAI team is addressing the third challenge by summarizing, extending, and applying psychologic theories of explanation to help the XAI evaluator define a suitable evaluation framework, which the developer teams will use to test their systems. The XAI teams completed the first of this 4-year program in May 2018. In a series of ongoing evaluations, the developer teams are assessing how well their XAM systems' explanations improve user understanding, user trust, and user task performance.},
    langid       = {english},
    file         = {/home/caribu/Zotero/storage/CTHBLVG9/AI Magazine - 2019 - Gunning - DARPA s Explainable Artificial Intelligence Program.pdf;/home/caribu/Zotero/storage/HJQX9QQA/Gunning y Aha - 2019 - DARPA's Explainable Artificial Intelligence Program.pdf;/home/caribu/Zotero/storage/HLI4I97H/aimag.v40i2.html}
}

@article{jassemDelaysDiagnosisTreatment2014,
    title        = {Delays in Diagnosis and Treatment of Breast Cancer: A Multinational Analysis},
    shorttitle   = {Delays in Diagnosis and Treatment of Breast Cancer},
    author       = {Jassem, Jacek and Ozmen, Vahit and Bacanu, Florin and Drobniene, Monika and Eglitis, Janis and Lakshmaiah, Kuntegowdanahalli C. and Kahan, Zsuzsanna and Mardiak, Jozef and Pieńkowski, Tadeusz and Semiglazova, Tatiana and Stamatovic, Ljiljana and Timcheva, Constanta and Vasovic, Suzana and Vrbanec, Damir and Zaborek, Piotr},
    date         = {2014-10-01},
    journaltitle = {European Journal of Public Health},
    shortjournal = {European Journal of Public Health},
    volume       = {24},
    number       = {5},
    pages        = {761--767},
    issn         = {1101-1262},
    doi          = {10.1093/eurpub/ckt131},
    url          = {https://doi.org/10.1093/eurpub/ckt131},
    urldate      = {2021-05-19},
    abstract     = {Background: Reducing treatment delay improves outcomes in breast cancer. The aim of this study was to determine factors influencing patient- and system-related delays in commencing breast cancer treatment in different countries. Methods: A total of 6588 female breast cancer patients from 12 countries were surveyed. Total delay time was determined as the sum of the patient-related delay time (time between onset of the first symptoms and the first medical visit) and system-related delay time (time between the first medical visit and the start of therapy). Results: The average patient-related delay time and total delay time were 4.7 (range: 3.4–6.2) weeks and 14.4 (range: 11.5–29.4) weeks, respectively. Longer patient-related delay times were associated with distrust and disregard, and shorter patient-related delay times were associated with fear of breast cancer, practicing self-examination, higher education level, being employed, having support from friends and family and living in big cities. The average system-related delay time was 11.1 (range: 8.3–24.7) weeks. Cancer diagnosis made by an oncologist versus another physician, higher education level, older age, family history of female cancers and having a breast lump as the first cancer sign were associated with shorter system-related delay times. Longer patient-related delay times and higher levels of distrust and disregard were predictors of longer system-related delay times. Conclusions: The delay in diagnosis and treatment of breast cancer remains a serious problem. Several psychological and behavioural patient attributes strongly determine both patient-related delay time and system-related delay time, but their strength is different in particular countries.},
    file         = {/home/caribu/Zotero/storage/AF55H7RQ/Jassem et al. - 2014 - Delays in diagnosis and treatment of breast cancer.pdf;/home/caribu/Zotero/storage/S8982N9K/474150.html}
}

@article{kimBreastDensity2024,
    title        = {Breast {{Density}}},
    author       = {Kim, Eric and Lewin, Alana A.},
    date         = {2024-07},
    journaltitle = {Radiologic Clinics of North America},
    shortjournal = {Radiologic Clinics of North America},
    volume       = {62},
    number       = {4},
    pages        = {593--605},
    issn         = {00338389},
    doi          = {10.1016/j.rcl.2023.12.007},
    url          = {https://linkinghub.elsevier.com/retrieve/pii/S0033838923002270},
    urldate      = {2025-01-20},
    langid       = {english},
    file         = {/home/caribu/Zotero/storage/WN3KLV3V/Kim y Lewin - 2024 - Breast Density.pdf}
}

@article{liaoClassificationAsymmetryMammography2023,
    title        = {Classification of Asymmetry in Mammography via the {{DenseNet}} Convolutional Neural Network},
    author       = {Liao, Tingting and Li, Lin and Ouyang, Rushan and Lin, Xiaohui and Lai, Xiaohui and Cheng, Guanxun and Ma, Jie},
    date         = {2023-12-01},
    journaltitle = {European Journal of Radiology Open},
    shortjournal = {European Journal of Radiology Open},
    volume       = {11},
    pages        = {100502},
    issn         = {2352-0477},
    doi          = {10.1016/j.ejro.2023.100502},
    url          = {https://www.sciencedirect.com/science/article/pii/S235204772300028X},
    urldate      = {2024-05-08},
    abstract     = {Purpose To investigate the effectiveness of a deep learning system based on the DenseNet convolutional neural network in diagnosing benign and malignant asymmetric lesions in mammography. Methods Clinical and image data from 460 women aged 23–82 years (47.57~±~8.73 years) with asymmetric lesions who underwent mammography at Shenzhen People's Hospital, Shenzhen Luohu District People's Hospital, and Shenzhen Hospital of Peking University from December 2019 to December 2020 were retrospectively analyzed. Two senior radiologists, two junior radiologists, and the DL system read the mammographic images of 460 patients, respectively, and finally recorded the BI-RADS classification of asymmetric lesions. We then used the area under the curve (AUC) of the receiver operating characteristic (ROC) to evaluate the diagnostic efficacy and the difference between AUCs by the Delong method. Results Specificity (0.909 vs. 0.835, 0.790, χ2=8.21 and 17.22, p＜0.05) and precision (0.872 vs. 0.763, 0.726, χ2=9.23 and 5.22, p＜0.05) of the DL system in the diagnosis of benign and malignant asymmetric lesions were higher than those of junior radiologist A and B, and there was a statistically significant difference between AUCs (0.778 vs. 0.579, 0.564, Z\,=\,4.033 and 4.460, p＜0.05). Furthermore, the AUC (0.778 vs. 0.904, 0.862, Z\,=\,3.191, and 2.167, p＜0.05) of benign and malignant asymmetric lesions diagnosed by the DL system was lower than that of senior radiologist A and senior radiologist B. Conclusions The DL system based on the DenseNet convolution neural network has high diagnostic efficiency, which can help junior radiologists evaluate benign and malignant asymmetric lesions more accurately. It can also improve diagnostic accuracy and reduce missed diagnoses caused by inexperienced junior radiologists.},
    keywords     = {Artificial Intelligence,Asymmetry,Deep learning,Mammography},
    file         = {/home/caribu/Zotero/storage/KBIWIK2X/Liao et al. - 2023 - Classification of asymmetry in mammography via the.pdf;/home/caribu/Zotero/storage/FXU9LITH/S235204772300028X.html}
}

@online{linFocalLossDense2018,
    title       = {Focal {{Loss}} for {{Dense Object Detection}}},
    author      = {Lin, Tsung-Yi and Goyal, Priya and Girshick, Ross and He, Kaiming and Dollár, Piotr},
    date        = {2018-02-07},
    eprint      = {1708.02002},
    eprinttype  = {arXiv},
    eprintclass = {cs},
    doi         = {10.48550/arXiv.1708.02002},
    url         = {http://arxiv.org/abs/1708.02002},
    urldate     = {2023-07-13},
    abstract    = {The highest accuracy object detectors to date are based on a two-stage approach popularized by R-CNN, where a classifier is applied to a sparse set of candidate object locations. In contrast, one-stage detectors that are applied over a regular, dense sampling of possible object locations have the potential to be faster and simpler, but have trailed the accuracy of two-stage detectors thus far. In this paper, we investigate why this is the case. We discover that the extreme foreground-background class imbalance encountered during training of dense detectors is the central cause. We propose to address this class imbalance by reshaping the standard cross entropy loss such that it down-weights the loss assigned to well-classified examples. Our novel Focal Loss focuses training on a sparse set of hard examples and prevents the vast number of easy negatives from overwhelming the detector during training. To evaluate the effectiveness of our loss, we design and train a simple dense detector we call RetinaNet. Our results show that when trained with the focal loss, RetinaNet is able to match the speed of previous one-stage detectors while surpassing the accuracy of all existing state-of-the-art two-stage detectors. Code is at: https://github.com/facebookresearch/Detectron.},
    pubstate    = {prepublished},
    version     = {2},
    keywords    = {Computer Science - Computer Vision and Pattern Recognition},
    file        = {/home/caribu/Zotero/storage/H29ENDXW/Lin et al. - 2018 - Focal Loss for Dense Object Detection.pdf;/home/caribu/Zotero/storage/9R438W5W/1708.html}
}

@article{madariagaBreastCancerTrends2024,
    title        = {Breast Cancer Trends in {{Chile}}: {{Incidence}} and Mortality Rates (2007–2018)},
    shorttitle   = {Breast Cancer Trends in {{Chile}}},
    author       = {Madariaga, Benjamín and Mondschein, Susana and Torres, Soledad},
    date         = {2024-06-27},
    journaltitle = {PLOS Global Public Health},
    shortjournal = {PLOS Global Public Health},
    volume       = {4},
    number       = {6},
    pages        = {e0001322},
    publisher    = {Public Library of Science},
    issn         = {2767-3375},
    doi          = {10.1371/journal.pgph.0001322},
    url          = {https://journals.plos.org/globalpublichealth/article?id=10.1371/journal.pgph.0001322},
    urldate      = {2025-07-31},
    abstract     = {Breast cancer (BC) is one of the most common cancers in women worldwide and in Chile. Due to the lack of a Chilean national cancer registry, there is partial information on the status of BC in the country. We aim to estimate BC incidence and mortality rates by health care providers and regions for Chilean women. We used two public anonymized databases provided by the Ministry of Health: the national death and hospital discharges datasets. We considered a cohort of 58,254 and 16,615 BC hospital discharges and deaths for the period 2007–2018. New BC cases increased by 43.6\%, from 3,785 in 2007 to 5,435 in 2018. Total BC deaths increased by 33.6\% from 1,158 to 1,547 during the same period. Age-adjusted incidence rates were stable over time, with an average rate of 44.0 cases/100,000 women (SD 2.2). There were considerable differences in age-adjusted incidence rates among regions, with no clear geographical trend. Women affiliated to a private provider (ISAPRE) have an average age-adjusted incidence rate of 60.6 compared to 38.8 (both cases/100,000 women) for women affiliated with the public provider (FONASA). Age-adjusted mortality rates have an average of 10.5 cases/100,000 women (SD 0.4). This study shows important differences in incidence rates between private and publicly insured women, with no significant differences in mortality rates. Such differences may be associated with women’s lifestyles, dietary compositions, comorbidities, and differences in healthcare systems. These hypotheses should be studied in greater depth. Additionally, differences in BC incidence found in this study compared to incidences reported from other estimations reinforce the need of a national cancer registry that should lead to more accurate indicators regarding BC in Chile.},
    langid       = {english},
    keywords     = {Breast cancer,Cancer detection and diagnosis,Cancer epidemiology,Cancer treatment,Chile (country),Death rates,Epidemiology,Health insurance},
    file         = {/home/caribu/Zotero/storage/VD4GPNAR/Madariaga et al. - 2024 - Breast cancer trends in Chile Incidence and mortality rates (2007–2018).pdf}
}

@article{melladoIdentifyingClinicallyRelevant2025,
    title        = {Identifying Clinically Relevant Findings in Breast Cancer Using Deep Learning and Feature Attribution on Local Views from High-Resolution Mammography},
    author       = {Mellado, Diego and Mayeta-Revilla, Leondry and Sotelo, Julio and Querales, Marvin and Godoy, Eduardo and Lever, Scarlett and Pardo, Fabian and Chabert, Steren and Salas, Rodrigo},
    date         = {2025-09-23},
    journaltitle = {Frontiers in Oncology},
    shortjournal = {Front. Oncol.},
    volume       = {15},
    publisher    = {Frontiers},
    issn         = {2234-943X},
    doi          = {10.3389/fonc.2025.1601929},
    url          = {https://www.frontiersin.org/journals/oncology/articles/10.3389/fonc.2025.1601929/full},
    urldate      = {2025-09-26},
    abstract     = {IntroductionEarly detection of breast cancer via mammography screening is essential to improve survival outcomes, particularly in low-resource settings such as the global south where diagnostic accessibility remains limited. Although Deep Neural Network (DNN) models have demonstrated high accuracy in breast cancer detection, their clinical adoption is impeded by a lack of interpretability.MethodsTo address this challenge, CorRELAX is proposed as an interpretable algorithm designed to quantify the relevance of localized regions within high-resolution mammographic images. CorRELAX evaluates the contribution of partial local information to the model’s global decision-making and computes correlations between intermediate feature representations and predictions to produce global heatmaps for lesion localization. The framework utilizes a DNN trained on multi-scale crops of annotated lesions to effectively capture a spectrum of lesion sizes.ResultsEvaluation on the VinDr-Mammo dataset yielded F1 Scores of 0.8432 for calcifications and 0.7392 for masses. Heatmap localization accuracy was assessed using the Pointing Game metric, with CorRELAX achieving average accuracies of 0.6358 based on model predictions and 0.5602 using the correlation maps, indicating robust lesion localization capabilities.DiscussionThese results demonstrate that CorRELAX generates interpretable coarse-segmentation maps that enhance automated lesion detection in mammography. The improved interpretability facilitates clinically reliable decision-making and addresses a critical barrier toward the integration of AI-based methods in breast cancer screening workflows.},
    langid       = {english},
    keywords     = {breast cancer,deep learning,explainable artificial intelligence,feature attribution,mammography,medical image analysis},
    file         = {/home/caribu/Zotero/storage/SPDNFWVS/Mellado et al. - 2025 - Identifying clinically relevant findings in breast cancer using deep learning and feature attributio.pdf}
}

@online{nguyenNovelMultiviewDeep2022,
    title       = {A Novel Multi-View Deep Learning Approach for {{BI-RADS}} and Density Assessment of Mammograms},
    author      = {Nguyen, Huyen T. X. and Tran, Sam B. and Nguyen, Dung B. and Pham, Hieu H. and Nguyen, Ha Q.},
    date        = {2022-04-17},
    eprint      = {2112.04490},
    eprinttype  = {arXiv},
    eprintclass = {eess},
    doi         = {10.48550/arXiv.2112.04490},
    url         = {http://arxiv.org/abs/2112.04490},
    urldate     = {2024-12-17},
    abstract    = {Advanced deep learning (DL) algorithms may predict the patient’s risk of developing breast cancer based on the Breast Imaging Reporting and Data System (BI-RADS) and density standards. Recent studies have suggested that the combination of multi-view analysis improved the overall breast exam classification. In this paper, we propose a novel multi-view DL approach for BI-RADS and density assessment of mammograms. The proposed approach first deploys deep convolutional networks for feature extraction on each view separately. The extracted features are then stacked and fed into a Light Gradient Boosting Machine (LightGBM) classifier to predict BI-RADS and density scores. We conduct extensive experiments on both the internal mammography dataset and the public dataset Digital Database for Screening Mammography (DDSM). The experimental results demonstrate that the proposed approach outperforms the single-view classification approach on two benchmark datasets by huge F1-score margins (+5\% on the internal dataset and +10\% on the DDSM dataset). These results highlight the vital role of combining multi-view information to improve the performance of breast cancer risk prediction.},
    langid      = {english},
    pubstate    = {prepublished},
    keywords    = {Computer Science - Computer Vision and Pattern Recognition,Electrical Engineering and Systems Science - Image and Video Processing},
    file        = {/home/caribu/Zotero/storage/EZWR2HZY/Nguyen et al. - 2022 - A novel multi-view deep learning approach for BI-RADS and density assessment of mammograms.pdf}
}

@online{nguyenVinDrMammoLargescaleBenchmark2022,
    title      = {{{VinDr-Mammo}}: {{A}} Large-Scale Benchmark Dataset for Computer-Aided Diagnosis in Full-Field Digital Mammography},
    shorttitle = {{{VinDr-Mammo}}},
    author     = {Nguyen, Hieu T. and Nguyen, Ha Q. and Pham, Hieu H. and Lam, Khanh and Le, Linh T. and Dao, Minh and Vu, Van},
    date       = {2022-03-10},
    eprinttype = {medRxiv},
    pages      = {2022.03.07.22272009},
    doi        = {10.1101/2022.03.07.22272009},
    url        = {https://www.medrxiv.org/content/10.1101/2022.03.07.22272009v1},
    urldate    = {2022-12-17},
    abstract   = {Mammography, or breast X-ray, is the most widely used imaging modality to detect cancer and other breast diseases. Recent studies have shown that deep learning-based computer-assisted detection and diagnosis (CADe/x) tools have been developed to support physicians and improve the accuracy of interpreting mammography. However, most published datasets of mammography are either limited on sample size or digitalized from screen-film mammography (SFM), hindering the development of CADe/x tools which are developed based on full-field digital mammography (FFDM). To overcome this challenge, we introduce VinDr-Mammo – a new benchmark dataset of FFDM for detecting and diagnosing breast cancer and other diseases in mammography. The dataset consists of 5,000 mammography exams, each of which has four standard views and is double read with disagreement (if any) being resolved by arbitration. It is created for the assessment of Breast Imaging Reporting and Data System (BI-RADS) and density at the breast level. In addition, the dataset also provides the category, location, and BI-RADS assessment of non-benign findings. We make VinDr-Mammo publicly available on https://physionet.org/ as a new imaging resource to promote advances in developing CADe/x tools for breast cancer screening.},
    langid     = {english},
    pubstate   = {prepublished},
    file       = {/home/caribu/Zotero/storage/4MCT3QAS/Nguyen et al. - 2022 - VinDr-Mammo A large-scale benchmark dataset for c.pdf}
}

@inproceedings{raffertyExplainableArtificialIntelligence2022,
    title      = {Explainable {{Artificial Intelligence}} for~{{Breast Tumour Classification}}: {{Helpful}} or~{{Harmful}}},
    shorttitle = {Explainable {{Artificial Intelligence}} for~{{Breast Tumour Classification}}},
    booktitle  = {Interpretability of {{Machine Intelligence}} in {{Medical Image Computing}}},
    author     = {Rafferty, Amy and Nenutil, Rudolf and Rajan, Ajitha},
    editor     = {Reyes, Mauricio and Henriques Abreu, Pedro and Cardoso, Jaime},
    date       = {2022},
    pages      = {104--123},
    publisher  = {Springer Nature Switzerland},
    location   = {Cham},
    doi        = {10.1007/978-3-031-17976-1_10},
    abstract   = {Explainable Artificial Intelligence (XAI) is the field of AI dedicated to promoting trust in machine learning models by helping us to understand how they make their decisions. For example, image explanations show us which pixels or segments were deemed most important by a model for a particular classification decision. This research focuses on image explanations generated by LIME, RISE and SHAP for a model which classifies breast mammograms as either benign or malignant. We assess these XAI techniques based on (1) the extent to which they agree with each other, as decided by One-Way ANOVA, Kendall’s Tau and RBO statistical tests, and (2) their agreement with the diagnostically important areas as identified by a radiologist on a small subset of mammograms. The main contribution of this research is the discovery that the 3 techniques consistently disagree both with each other and with the medical truth. We argue that using these off-shelf techniques in a medical context is not a feasible approach, and discuss possible causes of this problem, as well as some potential solutions.},
    isbn       = {978-3-031-17976-1},
    langid     = {english},
    file       = {/home/caribu/Zotero/storage/CSQN8CMH/Rafferty et al. - 2022 - Explainable Artificial Intelligence for Breast Tum.pdf}
}

@article{riccilaraAddressingFairnessArtificial2022,
    title        = {Addressing Fairness in Artificial Intelligence for Medical Imaging},
    author       = {Ricci Lara, María Agustina and Echeveste, Rodrigo and Ferrante, Enzo},
    date         = {2022-08-06},
    journaltitle = {Nature Communications},
    shortjournal = {Nat Commun},
    volume       = {13},
    number       = {1},
    pages        = {4581},
    publisher    = {Nature Publishing Group},
    issn         = {2041-1723},
    doi          = {10.1038/s41467-022-32186-3},
    url          = {https://www.nature.com/articles/s41467-022-32186-3},
    urldate      = {2026-01-05},
    abstract     = {A plethora of work has shown that AI systems can systematically and unfairly be biased against certain populations in multiple scenarios. The field of medical imaging, where AI systems are beginning to be increasingly adopted, is no exception. Here we discuss the meaning of fairness in this area and comment on the potential sources of biases, as well as the strategies available to mitigate them. Finally, we analyze the current state of the field, identifying strengths and highlighting areas of vacancy, challenges and opportunities that lie ahead.},
    langid       = {english},
    keywords     = {Image processing,Machine learning},
    file         = {/home/caribu/Zotero/storage/9XIYCHXH/Ricci Lara et al. - 2022 - Addressing fairness in artificial intelligence for medical imaging.pdf}
}

@book{sickles2013acr,
    title     = {{{ACR BI-RADS}}® {{Atlas}}, {{Breast Imaging Reporting}} and {{Data System}}},
    author    = {Sickles, Edward A and D’Orsi, Carl J and Mendelson, Ellen B and Morris, Elizabeth A},
    date      = {2013},
    edition   = {5},
    publisher = {American College of Radiology},
    location  = {Reston, VA},
    isbn      = {978-1-55903-016-8},
    pagetotal = {689}
}

@online{tanEfficientNetV2SmallerModels2021,
    title       = {{{EfficientNetV2}}: {{Smaller Models}} and {{Faster Training}}},
    shorttitle  = {{{EfficientNetV2}}},
    author      = {Tan, Mingxing and Le, Quoc V.},
    date        = {2021-06-23},
    eprint      = {2104.00298},
    eprinttype  = {arXiv},
    eprintclass = {cs},
    url         = {http://arxiv.org/abs/2104.00298},
    urldate     = {2023-11-09},
    abstract    = {This paper introduces EfficientNetV2, a new family of convolutional networks that have faster training speed and better parameter efficiency than previous models. To develop these models, we use a combination of training-aware neural architecture search and scaling, to jointly optimize training speed and parameter efficiency. The models were searched from the search space enriched with new ops such as Fused-MBConv. Our experiments show that EfficientNetV2 models train much faster than state-of-the-art models while being up to 6.8x smaller.},
    langid      = {english},
    pubstate    = {prepublished},
    keywords    = {Computer Science - Computer Vision and Pattern Recognition},
    file        = {/home/caribu/Zotero/storage/RPVC7ZZM/Tan y Le - 2021 - EfficientNetV2 Smaller Models and Faster Training.pdf}
}
